#!/bin/sh
#SBATCH --job-name=rstudio-server
#SBATCH --partition=small
#SBATCH --time=02:00:00
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --mem=20G
#SBATCH --signal=USR2
#SBATCH --output=%x_%j.out
# The following line specifies the work directory for this job.
#SBATCH --chdir=/scratch/htc/<username>/rstudio-server-sif/WORKDIR                       # Update this line

# This script will request a single CPU with four threads with 20GB of RAM for 2 hours.
# You can adjust --time, --nodes, --ntasks, and --mem above or on the sbatch command line to adjust these settings for your session.

# --output=%x_%j.out creates a output file called rstudio-server_NNNNNNNN.out, where the %x is short hand for --job-name above and the N's are an 8-digit. jobID assigned by SLURM when our job is submitted.

RSTUDIO_CWD="/scratch/htc/<username>/rstudio-server-sif/WORKDIR"                          # Update this line
RSTUDIO_SIF="/scratch/htc/<username>/rstudio-server-sif/rstudio_latest.sif"               # Update this line

# Create temp directory for ephemeral content to bind-mount in the container
RSTUDIO_TMP="$TMPDIR"

mkdir -p -m 700 \
 ${RSTUDIO_TMP}/run \
 ${RSTUDIO_TMP}/tmp \
 ${RSTUDIO_TMP}/var/lib/rstudio-server

cat > ${RSTUDIO_TMP}/database.conf <<END
provider=sqlite
directory=/var/lib/rstudio-server
END

# Set OMP_NUM_THREADS to prevent OpenBLAS (and any other OpenMP-enhanced libraries used by R) from spawning more threads than the number of processors
allocated to the job.

# Set R_LIBS_USER to a path specific to rocker/rstudio to avoid conflicts with personal libraries from any R installation in the host environment.

cat > ${RSTUDIO_TMP}/rsession.sh <<END

#!/bin/sh

export OMP_NUM_THREADS=${SLURM_JOB_CPUS_PER_NODE}
export R_LIBS_USER=${RSTUDIO_CWD}/R
export https_proxy=http://squid.zib.de:3128
export http_proxy=http://squid.zib.de:3128
exec /usr/lib/rstudio-server/bin/rsession "\${@}"
END

chmod +x ${RSTUDIO_TMP}/rsession.sh

export APPTAINER_BIND="${RSTUDIO_CWD}:${RSTUDIO_CWD},${RSTUDIO_TMP}/run:/run,${RSTUDIO_TMP}/tmp:/tmp,${RSTUDIO_TMP}/database.conf:/etc/rstudio/database.conf,${RSTUDIO_TMP}/rsession.sh:/etc/rstudio/rsession.sh,${RSTUDIO_TMP}/var/lib/rstudio-server:/var/lib/rstudio-server"

# Do not suspend idle sessions.
# Alternative to setting session-timeout-minutes=0 in /etc/rstudio/rsession.conf
export APPTAINERENV_RSTUDIO_SESSION_TIMEOUT=0

export APPTAINERENV_USER=$(id -un)
export APPTAINERENV_PASSWORD=$(openssl rand -base64 15)

# get unused socket per https://unix.stackexchange.com/a/132524
# tiny race condition between the python & apptainer commands
readonly PORT=$(/usr/bin/python3 -c 'import socket; s=socket.socket(); s.bind(("", 0)); print(s.getsockname()[1]); s.close()')
cat 1>&2 <<END

1. SSH tunnel from your workstation using the following command:

  ssh -N -L 8787:${HOSTNAME}:${PORT} ${APPTAINERENV_USER}@z1.zib.de

  and point your web browser to http://localhost:8787

2. log in to RStudio Server using the following credentials:

  user: ${APPTAINERENV_USER}
  password: ${APPTAINERENV_PASSWORD}

When done using RStudio Server, terminate the job by:

1. Exit the RStudio Session ("power" button in the top right corner of the RStudio window)
2. Issue the following command on the login node:

   scancel -f ${SLURM_JOB_ID}
END

export APPTAINERENV_http_proxy=http://squid.zib.de:3128
export APPTAINERENV_https_proxy=http://squid.zib.de:3128

apptainer exec --cleanenv --home ${RSTUDIO_CWD} ${RSTUDIO_SIF} \
  rserver --www-port ${PORT} \
      --auth-none=0 \
      --auth-pam-helper-path=pam-helper \
      --auth-stay-signed-in-days=30 \
      --auth-timeout-minutes=0 \
      --rsession-path=/etc/rstudio/rsession.sh \
      --server-user=${APPTAINERENV_USER}

APPTAINER_EXIT_CODE=$?
echo "rserver exited $APPTAINER_EXIT_CODE" 1>&2
exit $APPTAINER_EXIT_CODE